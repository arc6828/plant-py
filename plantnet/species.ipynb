{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Species - Plant Resources of South East Asia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json,codecs\n",
    "import pandas as pd\n",
    "from slugify import slugify\n",
    "\n",
    "# Step 1: Open and read the HTML file\n",
    "html_file_path = \"data/SEA-species.html\"  # Replace with your HTML file path\n",
    "with open(html_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    html_content = file.read()\n",
    "\n",
    "# Step 2: Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "# Find the <main> tag\n",
    "# main_tag = soup.find(\"main\")\n",
    "\n",
    "# Find the <div> tag with class \"container\"\n",
    "container_divs = soup.find_all(\"article\", class_=\"species-card\")\n",
    "\n",
    "# Find all <a> tags\n",
    "a_tags = []\n",
    "data = []\n",
    "for container_div in container_divs:\n",
    "    # a_tags += container_div.find_all(\"a\")\n",
    "    try:\n",
    "        \n",
    "        labels = [x.text.lower().strip() for x in container_div.find_all(\"div\", class_=\"pn-labeled-data-label\")]\n",
    "        contents = [x.text.lower().strip() for x in container_div.find_all(\"div\", class_=\"pn-labeled-data-content\")]\n",
    "        merged_dict = dict(zip(labels, contents))\n",
    "        original = {\n",
    "            \"common name\":\"\",\n",
    "            \"genus\":\"\",\n",
    "            \"family\":\"\",\n",
    "        }\n",
    "        merged_dict = original | merged_dict  # Merge dicts (dict2 values overwrite dict1)\n",
    "        card = {\n",
    "            \"species-name\" : container_div.find(\"h1\").text.strip(),\n",
    "            \"slug\" : slugify(container_div.find(\"h1\").text.strip()),\n",
    "            \"common-name\" : merged_dict[\"common name\"],\n",
    "            \"common-name-th\" : \"\",\n",
    "            \"genus\" : merged_dict[\"genus\"],\n",
    "            \"family\" : merged_dict[\"family\"],\n",
    "            \"images\" : [ x.get(\"src\") for x in container_div.find_all(\"img\")],\n",
    "            \"num-images\" : container_div.find_all(\"span\")[-2].text.replace(\",\", \"\").strip(),\n",
    "            \"num-observations\" : container_div.find_all(\"span\")[-1].text.replace(\",\", \"\").split(\" \")[0].strip(),\n",
    "        }\n",
    "        data.append(card);\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        print(container_div.find(\"h1\").text.strip())\n",
    "    \n",
    "    # break;\n",
    "\n",
    "#data\n",
    "df = pd.DataFrame(data)\n",
    "# df[\"common-name-th\"] = df[\"common-name\"]\n",
    "\n",
    "\n",
    "filename = \"data/SEA-species.xlsx\"\n",
    "df.to_excel(filename, index=False)  # บันทึกเป็น Excel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load JSON file into DataFrame\n",
    "filename = \"data/SEA-species.csv\"\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "# แปลง DataFrame เป็น JSON\n",
    "json_file = \"data/SEA-species.json\"\n",
    "df.to_json(json_file, orient=\"records\", lines=False, force_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Load JSON file into DataFrame\n",
    "filename = \"data/SEA-species.json\"\n",
    "df = pd.read_json(filename)\n",
    "\n",
    "#Translator\n",
    "translator = Translator()\n",
    "\n",
    "#Translate\n",
    "texts = list(df[\"common-name\"])\n",
    "\n",
    "# Create an example array of 1000 strings (or any multiple of 100)\n",
    "texts = np.array(texts)\n",
    "texts = np.pad(texts,(0,62),constant_values=-1)\n",
    "\n",
    "# Reshape array to have 100 elements per row\n",
    "reshaped_array = texts.reshape(-1, 100)\n",
    "\n",
    "\n",
    "answers = []\n",
    "for index, row in enumerate(reshaped_array):\n",
    "    translations  = await translator.translate(row.tolist(), dest = 'th')\n",
    "    answers = answers + [x.text for x in translations]\n",
    "    print(index)\n",
    "    # Sleep for 5 seconds\n",
    "    time.sleep(5)\n",
    "    # break\n",
    "\n",
    "texts = np.array(answers)\n",
    "filtered_list = texts[texts != \"-1\"].tolist()\n",
    "\n",
    "df[\"common-name-th\"] =  filtered_list\n",
    "\n",
    "# แปลง DataFrame เป็น JSON\n",
    "json_file = \"data/SEA-species-th.json\"\n",
    "df.to_json(json_file, orient=\"records\", lines=False, force_ascii=False, indent=4)\n",
    "\n",
    "filename = \"data/SEA-species-th.xlsx\"\n",
    "df.to_excel(filename, index=False)  # บันทึกเป็น Excel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plant-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
